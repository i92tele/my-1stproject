# AutoFarming Bot Integration Test Suite

This comprehensive integration test suite validates all major components of the AutoFarming Bot system, ensuring everything works together correctly.

## ğŸ¯ What It Tests

### 1. **Worker Rotation** (`test_worker_rotation`)
- âœ… Worker availability checking
- âœ… Worker usage tracking
- âœ… Cooldown management
- âœ… Rotation logic
- âœ… Worker health monitoring

### 2. **Test Group Posting** (`test_test_group_posting`)
- âœ… Managed group retrieval
- âœ… Test ad slot creation
- âœ… Content management
- âœ… Posting simulation (without actual posting)
- âœ… Post logging

### 3. **Payment Creation & Verification** (`test_payment_creation_and_verification`)
- âœ… Payment creation with unique IDs
- âœ… Payment retrieval and status checking
- âœ… Pending payment monitoring
- âœ… Payment verification simulation
- âœ… Subscription activation after payment

### 4. **Complete User Flow** (`test_complete_user_flow`)
- âœ… User registration
- âœ… Subscription selection
- âœ… Payment processing
- âœ… Subscription activation
- âœ… Ad slot creation
- âœ… Content setup
- âœ… Destination configuration
- âœ… Posting cycle simulation

### 5. **Database Operations** (`test_database_operations`)
- âœ… User CRUD operations
- âœ… Subscription management
- âœ… Ad slot operations
- âœ… Group management
- âœ… Statistics retrieval

## ğŸš€ How to Run

### Basic Usage
```bash
# Run all tests
python3 test_integration.py

# Or use the test runner
python3 run_integration_tests.py
```

### Advanced Usage
```bash
# Run specific test category
python3 run_integration_tests.py --test worker
python3 run_integration_tests.py --test payment
python3 run_integration_tests.py --test posting
python3 run_integration_tests.py --test flow

# Run with verbose logging
python3 run_integration_tests.py --verbose

# Run quick tests only
python3 run_integration_tests.py --quick
```

## ğŸ“Š Understanding Results

### Test Output
The test suite provides detailed logging for each step:

```
ğŸ§ª AutoFarming Bot Integration Test Suite
==================================================
ğŸš€ Initializing Integration Test Suite...
âœ… Configuration loaded successfully
âœ… Database initialized successfully
âœ… All components initialized successfully
ğŸ¯ Integration test suite ready!
ğŸ”„ Testing Worker Rotation...
ğŸ“Š Found 5 available workers
ğŸ§ª Testing worker 1
âœ… Worker usage updated
â° Worker cooldown status: False
âœ… Worker rotation completed
âœ… Worker rotation test completed successfully
```

### Test Report
At the end, you'll get a comprehensive report:

```
ğŸ“ˆ TEST RESULTS SUMMARY:
Total Tests: 5
Passed: 5
Failed: 0
Success Rate: 100.0%

ğŸ“‹ DETAILED RESULTS:
âœ… worker_rotation: PASS
âœ… payment_creation_verification: PASS
âœ… test_group_posting: PASS
âœ… complete_user_flow: PASS
âœ… database_operations: PASS

ğŸ‰ ALL TESTS PASSED! Integration test suite completed successfully.
```

## ğŸ“ Files Created

### Log Files
- `test_integration.log` - Detailed test execution logs
- Console output - Real-time test progress

### Test Data
The tests create temporary test data in your database:
- Test users (IDs: 123456789, 987654321, 555666777, 111222333)
- Test payments with unique IDs
- Test ad slots and content
- Test group entries

## ğŸ”§ Configuration Requirements

### Environment Variables
Make sure these are set in your `.env` file:
```env
BOT_TOKEN=your_bot_token
DATABASE_URL=your_database_url
ADMIN_ID=your_admin_id
```

### Dependencies
The test suite requires:
- `python-dotenv` - For environment variable loading
- `asyncpg` - For database operations
- `python-telegram-bot` - For bot functionality
- All your custom modules (config, database, commands, etc.)

## ğŸ› Troubleshooting

### Common Issues

1. **Import Errors**
   ```
   âŒ Error importing test modules: No module named 'config'
   ```
   **Solution**: Make sure you're running from the project root directory.

2. **Database Connection Errors**
   ```
   âŒ Database initialization error: connection failed
   ```
   **Solution**: Check your `DATABASE_URL` in the `.env` file.

3. **Missing Components**
   ```
   âš ï¸ Some components not available - limited testing
   ```
   **Solution**: Install missing dependencies or check file paths.

### Debug Mode
Run with verbose logging to see detailed information:
```bash
python3 run_integration_tests.py --verbose
```

## ğŸ“ˆ Test Coverage

### What's Tested
- âœ… Database operations and connections
- âœ… Worker management and rotation
- âœ… Payment processing workflow
- âœ… User subscription flow
- âœ… Ad slot management
- âœ… Content posting simulation
- âœ… Error handling and logging

### What's NOT Tested
- âŒ Actual Telegram API calls (to avoid spam)
- âŒ Real blockchain transactions
- âŒ Actual worker account authentication
- âŒ Real group joining/posting

## ğŸ”„ Continuous Integration

### Automated Testing
You can integrate this into your CI/CD pipeline:

```yaml
# Example GitHub Actions workflow
- name: Run Integration Tests
  run: |
    python3 run_integration_tests.py --verbose
    if [ $? -ne 0 ]; then
      echo "Integration tests failed"
      exit 1
    fi
```

### Pre-deployment Testing
Run before deploying to production:
```bash
# Quick test before deployment
python3 run_integration_tests.py --quick

# Full test for major releases
python3 run_integration_tests.py --verbose
```

## ğŸ“ Customization

### Adding New Tests
To add a new test, modify `test_integration.py`:

```python
async def test_your_new_feature(self):
    """Test your new feature."""
    logger.info("ğŸ§ª Testing Your New Feature...")
    
    try:
        # Your test logic here
        self.test_results['your_new_feature'] = 'PASS'
        logger.info("âœ… Your new feature test completed successfully")
        
    except Exception as e:
        logger.error(f"âŒ Your new feature test failed: {e}")
        self.test_results['your_new_feature'] = 'FAIL'
```

### Modifying Test Data
Adjust test user IDs, content, or other parameters in the test methods to match your specific requirements.

## ğŸ¯ Best Practices

1. **Run tests before deployment** - Always test before pushing to production
2. **Check logs** - Review `test_integration.log` for detailed information
3. **Clean test data** - Remove test data from production databases
4. **Monitor performance** - Watch for slow database operations
5. **Update tests** - Keep tests in sync with code changes

## ğŸ“ Support

If you encounter issues with the integration tests:

1. Check the logs in `test_integration.log`
2. Verify your environment configuration
3. Ensure all dependencies are installed
4. Run with `--verbose` for detailed debugging

The test suite is designed to be comprehensive yet safe, providing confidence that your bot system is working correctly without interfering with production data. 